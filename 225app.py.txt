from flask import Flask, request, jsonify, render_template
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

app = Flask(__name__)

# Página inicial (HTML com o formulário de busca)
@app.route('/')
def index():
    return render_template('index.html')

# Rota para buscar resultados com base na consulta
@app.route('/buscar', methods=['GET'])
def buscar():
    query = request.args.get('query')  # Consulta enviada pelo usuário
    if not query:
        return "Erro: Nenhuma palavra-chave fornecida."

    # Sites para buscar resultados
    sites = [
        "https://www.python.org",
        "https://flask.palletsprojects.com",
    ]

    resultados = []
    for site in sites:
        try:
            response = requests.get(site)
            response.raise_for_status()  # Verifica erros HTTP
            soup = BeautifulSoup(response.text, 'html.parser')

            # Busca o termo na página
            for link in soup.find_all('a', href=True):
                titulo = link.get_text(strip=True)
                url_link = link['href']
                url_link = urljoin(site, url_link)  # Normaliza URLs relativas

                if query.lower() in titulo.lower():  # Verifica se o termo está no título
                    resultados.append({"titulo": titulo, "url": url_link})
        except Exception as e:
            print(f"Erro ao acessar {site}: {e}")

    # Retorna os resultados como JSON
    return jsonify(resultados)

if __name__ == '__main__':
    app.run(debug=True)

@app.route('/buscar', methods=['GET'])
def buscar():
    query = request.args.get('query')  # Consulta enviada pelo usuário
    if not query:
        return "Erro: Nenhuma palavra-chave fornecida."

    sites = [
        "https://www.python.org",
        "https://flask.palletsprojects.com",
    ]

    resultados = []
    for site in sites:
        try:
            response = requests.get(site)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            for link in soup.find_all('a', href=True):
                titulo = link.get_text(strip=True)
                url_link = urljoin(site, link['href'])

                if query.lower() in titulo.lower():
                    resultados.append({"titulo": titulo, "url": url_link})
        except Exception as e:
            print(f"Erro ao acessar {site}: {e}")

    return render_template('resultados.html', query=query, resultados=resultados)

